###### tags:

TreeSet, HashMap

###### date:

[1point3acres link](https://www.1point3acres.com/bbs/forum.php?mod=viewthread&tid=943884&ctid=234491)

## **Description**

coding 是祖传面试题，revenue。题目大意是 databricks 有一堆 customer，每个 customer 有对应的 revenue。需要支持三个 API：
int insert(int revenue)  /_ Insert a new customer to the system, with the given revenue. Return the new customer ID _/
int insert(int revenue, int referrer)  /_ Insert a new customer to the system, with the given revenue, and revenue also added to the referrer. Return the new customer ID _/
vector<int> get*lowest_k_by_total_revenue(int k, int min_total_revenue)  /* Get the k customers with the lowest revenue but have revenue above the min*total_revenue. Return the vector of customer IDs that satisfy the condition */

#### Example 1

Test case 1
int id1 = db.insert(1000); // Customer 0
int id2 = db.insert(1500, id1); // Customer 1
int id3 = db.insert(1200, id2); // Customer 2
int id4 = db.insert(800); // Customer 3
int id5 = db.insert(2000, id4); // Customer 4
int id6 = db.insert(500); // Customer 5
System.out.println(db.get_lowest_k_by_total_revenue(3, 1000)); // Expected output: [2, 4, 0]

#### Example 2

Databricks db2 = new Databricks();
int idA = db2.insert(3000); // Customer 0
int idB = db2.insert(5000, idA); // Customer 1
int idC = db2.insert(4000); // Customer 2
int idD = db2.insert(7000, idC); // Customer 3
int idE = db2.insert(2000, idD); // Customer 4
System.out.println(db2.get_lowest_k_by_total_revenue(2, 3000)); // Expected output: [0, 1]

#### Example 3

// Test case 3
Databricks db3 = new Databricks();
int idX = db3.insert(1000); // Customer 0
int idY = db3.insert(500, idX); // Customer 1
int idZ = db3.insert(300, idY); // Customer 2
System.out.println(db3.get_lowest_k_by_total_revenue(2, 100)); // Expected output: [2, 1]

In the second test case, Customers 0 and 2 have the lowest total revenue above 3000.

In the third test case, Customers 2 and 1 have the lowest total revenue above 100.

#### Constraints

Want to have the read operation to be efficient

## **Solution**

### Approach 1 (optimized for read operations):

##### Code:

```JAVA

import java.util.*;


class Customer implements Comparable<Customer>{
    int revenue;
    int totalRevenue;
    int id;
    public Customer(int id, int revenue){
        this.revenue += revenue;
        totalRevenue += revenue;
        this.id = id;
    }

    @Override
    public int compareTo(Customer c){
        return this.totalRevenue - c.totalRevenue;
    }

}


class Databricks{


    private int idCounter = 0;
    private HashMap<Integer, Customer> map = new HashMap<>();
    private TreeSet<Customer> sortedCustomers = new TreeSet<>();


    public int insert(int revenue){
        Customer customer = new Customer(idCounter++, revenue);
        map.put(idCounter, customer);

        sortedCustomers.add(customer);
        return customer.id;
    }

    public int insert(int revenue, int referrerCustomerId){
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);

        sortedCustomers.add(customer);

        Customer referrerCustomer = map.get(referrerCustomerId);
        if(referrerCustomer != null){
            referrerCustomer.totalRevenue += revenue;
            sortedCustomers.remove(referrerCustomer);
            sortedCustomers.add(referrerCustomer);
        }
        return customer.id;
    }

    public List<Integer> getLowestKByTotalRevenue(int k, int minTotalRevenue){

        List<Integer> list = new LinkedList<>();
        for(Customer customer : sortedCustomers){

            if(list.size() < k && customer.totalRevenue >= minTotalRevenue){
                list.add(customer.id);
                if(list.size() == k){
                    break;
                }
            }


        }
        return list;

    }




}



public class Main {
    public static void main(String[] args) {
        Databricks db = new Databricks();

        // Test case 1
        int id1 = db.insert(1000); // Customer 0
        int id2 = db.insert(1500, id1); // Customer 1
        int id3 = db.insert(1200, id2); // Customer 2
        int id4 = db.insert(800); // Customer 3
        int id5 = db.insert(2000, id4); // Customer 4
        int id6 = db.insert(500); // Customer 5
        System.out.println(db.getLowestKByTotalRevenue(3, 1000)); // Expected output: [2, 4, 0]

        // Test case 2
        Databricks db2 = new Databricks();
        int idA = db2.insert(3000); // Customer 0
        int idB = db2.insert(5000, idA); // Customer 1
        int idC = db2.insert(4000); // Customer 2
        int idD = db2.insert(7000, idC); // Customer 3
        int idE = db2.insert(2000, idD); // Customer 4
        System.out.println(db2.getLowestKByTotalRevenue(2, 3000)); // Expected output: [0, 2]

        // Test case 3
        Databricks db3 = new Databricks();
        int idX = db3.insert(1000); // Customer 0
        int idY = db3.insert(500, idX); // Customer 1
        int idZ = db3.insert(300, idY); // Customer 2
        System.out.println(db3.getLowestKByTotalRevenue(2, 100)); // Expected output: [2, 1]
    }
}


```

##### Complexity:

insert(int revenue):

Time complexity: The time complexity for adding a new customer is O(log N) because we need to add the customer to the TreeSet, which is implemented as a Red-Black Tree.

Space complexity: The space complexity is O(N) as each new customer is stored in a Map and a TreeSet.

insert(int revenue, int referrer):

Time complexity: In this case, we have to first retrieve the referrer customer, update its revenue, and add it back to the TreeSet. Each operation has a time complexity of O(log N), so overall, it's still O(log N).

Space complexity: The space complexity is also O(N) for the same reason as the first insert operation.

get_lowest_k_by_total_revenue(int k, int min_total_revenue):

Time complexity: This operation iterates over the sorted customers until it finds k customers who meet the conditions. In the worst case, it might need to iterate through all the customers, so the time complexity is O(N).

Space complexity: The space complexity is O(k), where k is the number of customers returned in the result list. It can also be seen as O(1) if we consider k to be a small constant.

Overall, the space complexity of the entire class is O(N) as we're storing all the customers in a Map and a TreeSet. The time complexity for insert operations is O(log N), while for the get operation, it's O(N).

## **Reference**

### Approach 2 (optimized for write operations):

```JAVA
import java.util.*;

class Customer {
    int revenue;
    int totalRevenue;
    int id;

    public Customer(int id, int revenue){
        this.revenue = revenue;
        this.totalRevenue = revenue;
        this.id = id;
    }
}

class Databricks {
    private int idCounter = 0;
    private HashMap<Integer, Customer> map = new HashMap<>();
    private List<Customer> customers = new ArrayList<>();

    public int insert(int revenue) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);
        customers.add(customer);
        return customer.id;
    }

    public int insert(int revenue, int referrerCustomerId) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);
        customers.add(customer);

        Customer referrerCustomer = map.get(referrerCustomerId);
        if (referrerCustomer != null) {
            referrerCustomer.totalRevenue += revenue;
        }
        return customer.id;
    }

    public List<Integer> getLowestKByTotalRevenue(int k, int minTotalRevenue) {
        List<Customer> sortedList = new ArrayList<>(customers);
        sortedList.sort(Comparator.comparingInt(c -> c.totalRevenue));

        List<Integer> result = new ArrayList<>();
        for (Customer customer : sortedList) {
            if (customer.totalRevenue >= minTotalRevenue) {
                result.add(customer.id);
                if (result.size() == k) {
                    break;
                }
            }
        }
        return result;
    }
}

public class Main {
    public static void main(String[] args) {

        Databricks db = new Databricks();
        // Test case 1
        int id1 = db.insert(1000); // Customer 0
        int id2 = db.insert(1500, id1); // Customer 1
        int id3 = db.insert(1200, id2); // Customer 2
        int id4 = db.insert(800); // Customer 3
        int id5 = db.insert(2000, id4); // Customer 4
        int id6 = db.insert(500); // Customer 5
        System.out.println(db.getLowestKByTotalRevenue(3, 1000)); // Expected output: [2, 4, 0]
    }
}

```

##### Complexity:

Time:
insert() : O(1)
insert(int revenue, int referrerCustomerId) : O(1)
getLowestKByTotalRevenue O(nlogn) because of the sorting

Therefore the overral time complexity is O(nlogn)

Space Complexity:
HashMap<Integer, Customer> map: The space complexity is
O(n), where n is the number of customers.

List<Customer> customers: The space complexity is also
O(n).

The overall space complexity of the Databricks class is
O(n).

如果我们想算 indirect-referer 的 revenue 怎么办。比如 2 refer 1，1 refer 0， 然后我们想算 0 的 overall revenue。输入还包括一个 depth，当 depth=0 就是只算自己，=1 就是 revenue 再加上 direct referer。

1. write-optimized 给每个 customer 记录一个 children list，然后只有在 get revenue 的时候再去用 DFS/BFS 算 total revenue

### Approach 3

```JAVA
import java.util.*;

class Customer {
    int revenue;
    int totalRevenue;
    int id;
    List<Integer> children;

    public Customer(int id, int revenue) {
        this.revenue = revenue;
        this.totalRevenue = revenue;
        this.id = id;
        this.children = new ArrayList<>();
    }
}

class Databricks {
    private int idCounter = 0;
    private HashMap<Integer, Customer> map = new HashMap<>();

    public int insert(int revenue) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);
        return customer.id;
    }

    public int insert(int revenue, int referrerCustomerId) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);

        Customer referrerCustomer = map.get(referrerCustomerId);
        if (referrerCustomer != null) {
            referrerCustomer.children.add(customer.id);
        }
        return customer.id;
    }

    public int getOverallRevenue(int customerId, int depth) {
        int total = 0;
        Queue<Pair<Integer, Integer>> queue = new LinkedList<>(); // Pair of customer ID and current depth
        queue.add(new Pair<>(customerId, 0));

        while (!queue.isEmpty()) {
            Pair<Integer, Integer> pair = queue.poll();
            int currentId = pair.getKey();
            int currentDepth = pair.getValue();

            Customer customer = map.get(currentId);
            total += customer.revenue;

            if (currentDepth < depth) {
                for (int childId : customer.children) {
                    queue.add(new Pair<>(childId, currentDepth + 1));
                }
            }
        }

        return total;
    }

    static class Pair<K, V> {
        private K key;
        private V value;

        public Pair(K key, V value) {
            this.key = key;
            this.value = value;
        }

        public K getKey() {
            return key;
        }

        public V getValue() {
            return value;
        }
    }
}

public class Main {
    public static void main(String[] args) {
        Databricks db = new Databricks();

        int id0 = db.insert(1000); // Customer 0
        int id1 = db.insert(500, id0); // Customer 1
        int id2 = db.insert(300, id1); // Customer 2

        System.out.println(db.getOverallRevenue(id0, 0)); // Expected output: 1000
        System.out.println(db.getOverallRevenue(id0, 1)); // Expected output: 1500 (1000 from 0 + 500 from 1)
        System.out.println(db.getOverallRevenue(id0, 2)); // Expected output: 1800 (1000 from 0 + 500 from 1 + 300 from 2)
    }
}


```

#### Complexity:

Time complexity: both insert are constant O(1) but the getOverall is O(n) as it traverses the BFS

Space complexity: O(n) as the hashmap takes all the customers

2. read-optimized 每个 customer 都 maintain 一个 total revenue list， total revenue list 每个 element 对应不同的 depth。这个需要你每次 insert 的时候 maintain 这个结构，但你在 get revenue 的时候就可以直接读，不用计算。

```JAVA

import java.util.*;

class Customer {
    int revenue;
    List<Integer> children;
    List<Integer> totalRevenues;
    int id;

    public Customer(int id, int revenue) {
        this.id = id;
        this.revenue = revenue;
        this.children = new ArrayList<>();
        this.totalRevenues = new ArrayList<>();
        this.totalRevenues.add(revenue); // depth 0
    }
}

class Databricks {
    private int idCounter = 0;
    private HashMap<Integer, Customer> map = new HashMap<>();

    public int insert(int revenue) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);
        return customer.id;
    }

    public int insert(int revenue, int referrerCustomerId) {
        Customer customer = new Customer(idCounter++, revenue);
        map.put(customer.id, customer);

        Customer referrer = map.get(referrerCustomerId);
        if (referrer != null) {
            referrer.children.add(customer.id);
            updateTotalRevenues(referrer, revenue, 1);
        }
        return customer.id;
    }

    private void updateTotalRevenues(Customer customer, int addedRevenue, int depth) {
        while (customer.totalRevenues.size() <= depth) {
            customer.totalRevenues.add(customer.totalRevenues.get(customer.totalRevenues.size() - 1));
        }

        customer.totalRevenues.set(depth, customer.totalRevenues.get(depth) + addedRevenue);

        for (int childId : customer.children) {
            Customer child = map.get(childId);
            updateTotalRevenues(child, addedRevenue, depth + 1);
        }
    }

    public int getRevenueForDepth(int customerId, int depth) {
        Customer customer = map.get(customerId);
        if (customer.totalRevenues.size() > depth) {
            return customer.totalRevenues.get(depth);
        } else {
            return -1;  // return -1 or a suitable value if the depth is not available
        }
    }
}

public class Main {
    public static void main(String[] args) {
        Databricks db = new Databricks();

        int id0 = db.insert(1000); // Customer 0
        int id1 = db.insert(500, id0); // Customer 1
        int id2 = db.insert(300, id1); // Customer 2

        System.out.println(db.getRevenueForDepth(id0, 0)); // Expected output: 1000
        System.out.println(db.getRevenueForDepth(id0, 1)); // Expected output: 1500
        System.out.println(db.getRevenueForDepth(id0, 2)); // Expected output: 1800
    }
}


```

#### Complexity:

Time:
the overal worst-case time complexity is O(n^2) but in practice is will be closer to linear time

Space:
O(n)
